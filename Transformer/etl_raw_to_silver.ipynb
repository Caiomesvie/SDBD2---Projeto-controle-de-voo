{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8062844",
   "metadata": {},
   "source": [
    "# ETL da camada bronze para camada silver\n",
    "\n",
    "Este notebook realiza o ETL dos dados da camada bronze para a camada silver. Ou seja: ele abre o dataset e o salva num dataframe, realiza a transformação dos dados e os carrega num arquivo `.csv` e no banco de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff15ea4",
   "metadata": {},
   "source": [
    "### Estratégia de Leitura Otimizada (Chunking)\n",
    "\n",
    "Para contornar as limitações de memória do ambiente WSL ao ler o arquivo `MICRODADOS_ENEM_2021.csv` (>1GB), adotamos a estratégia de leitura em lotes (*chunks*).\n",
    "Diferente do padrão do Pandas que tenta carregar todo o arquivo na RAM, este método cria um iterador que processa o arquivo em fragmentos sequenciais, similar ao comportamento \"lazy\" do Apache Spark.\n",
    "\n",
    "**Parâmetros Críticos:**\n",
    "* `chunksize=100000`: Limita o consumo de RAM processando apenas 100 mil linhas por vez.\n",
    "* `encoding='ISO-8859-1'`: Corrige erros de decodificação de caracteres que contem dentro do arquivo `MICRODADOS_ENEM_2021.csv` que e um \"erro\" bem comuns em dados  usado no Brasil.\n",
    "* `sep=';'`: Define o ponto e vírgula como separador correto, evitando que o dataset seja lido em uma única coluna e assim trazendo como esperamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd739d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data_layer_filepath = '../raw/'\n",
    "\n",
    "chunk_size = 100000\n",
    "\n",
    "chunks = pd.read_csv(\n",
    "    data_layer_filepath + 'data_raw/MICRODADOS_ENEM_2021.csv', \n",
    "    low_memory=False, \n",
    "    encoding='ISO-8859-1', \n",
    "    sep=';', \n",
    "    chunksize=chunk_size\n",
    ")\n",
    "\n",
    "print(\"Leitura em chunks iniciada...\")\n",
    "\n",
    "contagem_total_linhas = 0\n",
    "\n",
    "for df_chunk in chunks:\n",
    "    print(df_chunk.head())\n",
    "    \n",
    "    contagem_total_linhas += len(df_chunk)\n",
    "\n",
    "print(f\"Processamento finalizado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
